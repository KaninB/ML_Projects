{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 -  MLP\n",
    "\n",
    "## Setup Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "class_1 = [1,0,0]\n",
    "class_2 = [0,1,0]\n",
    "class_3 = [0,0,1]\n",
    "\n",
    "def convert(data):\n",
    "    temp = []\n",
    "    for y in data:\n",
    "        if y == 1:\n",
    "            temp += [class_1]\n",
    "        elif y == 2:\n",
    "            temp += [class_2]\n",
    "        elif y == 3:\n",
    "            temp += [class_3]\n",
    "    return(temp)\n",
    "\n",
    "def decode(encoded_class):\n",
    "    print(encoded_class)\n",
    "    classes = [class_1, class_2, class_3]\n",
    "    for idx in range(len(classes)):\n",
    "        if not (encoded_class-classes[idx]).any():\n",
    "            return idx+1\n",
    "        \n",
    "def decode_spec(encoded_class):\n",
    "    classes = [class_1, class_2, class_3]\n",
    "    for idx in range(len(classes)):\n",
    "        if not encoded_class ==classes[idx]:\n",
    "            return idx+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "                 'machine-learning-databases/wine/wine.data', names=(\n",
    "                                            'Class', \n",
    "                                            'Alcohol', \n",
    "                                            'Malic acid',\n",
    "                                            'Ash', \n",
    "                                            'Alcalinity of ash',\n",
    "                                            'Magnesium', \n",
    "                                            'Total phenols',\n",
    "                                            'Flavanoids', \n",
    "                                            'Nonflavanoid phenols',\n",
    "                                            'Proanthocyanins', \n",
    "                                            'Color intensity',\n",
    "                                            'Hue', \n",
    "                                            'OD280/OD315 of diluted wines',\n",
    "                                            'Proline' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df, df['Class'], test_size=0.2)\n",
    "x_train =(x_train-x_train.min())/(x_train.max()-x_train.min())\n",
    "x_test =(x_test-x_test.min())/(x_test.max()-x_test.min())\n",
    "x_train = x_train.drop(['Class'], axis=1).to_numpy()\n",
    "x_test = x_test.drop(['Class'], axis=1).to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "y_train = np.array(convert(y_train))\n",
    "y_test = np.array(convert(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Chance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_error(actual, predict):\n",
    "    return abs(actual-predict)/abs(predict)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Error: 66.75352112676067\n"
     ]
    }
   ],
   "source": [
    "#Since model is random, simulate multiple times and find a true average\n",
    "avg_true = 0\n",
    "simulate = 1000\n",
    "for i in range(simulate):\n",
    "    class_cnts = {\"1\":0, \"2\":0, \"3\":0}\n",
    "\n",
    "    for x in range(len(y_train)):\n",
    "        x = np.random.randint(3)+1\n",
    "        class_cnts[str(x)] += 1\n",
    "\n",
    "    avg_true += percent_error(class_cnts[\"1\"], sum(class_cnts.values()))\n",
    "print(\"Percent Error: \" + str(avg_true/simulate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return(1/(1 + np.exp(-x)))\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    e_x /= e_x.sum()\n",
    "    trash = np.zeros(len(e_x))\n",
    "    trash[np.argmax(e_x)] = 1\n",
    "    return trash\n",
    "\n",
    "def selection(x):\n",
    "    return(softmax(x))\n",
    "\n",
    "def generate_wt(x, y):\n",
    "    l =[]\n",
    "    for i in range(x):\n",
    "        l.append(np.random.uniform(-1,1,y))\n",
    "    return(np.array(l).reshape(x, y))\n",
    "\n",
    "def dot_product(nodes, weights):\n",
    "    d_fixed = []\n",
    "    for val in nodes:\n",
    "        temp = []\n",
    "        for weight in weights:\n",
    "            temp += [weight*val]\n",
    "        d_fixed += [temp]\n",
    "    d_fixed = np.array(d_fixed)\n",
    "    return(d_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def forward(x, w1, w2):\n",
    "    z1 = x.dot(w1)# input from layer 1\n",
    "    a1 = sigmoid(z1)# out put of layer 2\n",
    "\n",
    "    z2 = a1.dot(w2)# input of out layer\n",
    "    a2 = softmax(z2)# output of out layer\n",
    "    return(a2)\n",
    "\n",
    "def loss(out, Y):\n",
    "    s =(np.square(out.astype(int)-Y))\n",
    "    s = np.sum(s)\n",
    "    return(s)\n",
    "\n",
    "def back_prop(x, y, w1_in, w2_in, alpha):\n",
    "     \n",
    "    # hidden layer\n",
    "    z1 = x.dot(w1_in)# input from layer 1\n",
    "    a1 = sigmoid(z1)# output of layer 2\n",
    "     \n",
    "    # Output layer\n",
    "    z2 = a1.dot(w2_in)# input of out layer\n",
    "    a2 = softmax(z2)# output of out layer\n",
    "    \n",
    "    # error in output layer\n",
    "    d2 = (a2-y)\n",
    "    temp1 = w2_in.dot(d2.T)\n",
    "    temp2 = np.multiply(a1, 1-a1)\n",
    "    d1 = np.multiply(temp1.T, temp2)\n",
    " \n",
    "    # Gradient for w1 and w2\n",
    "    w1_adj = dot_product(x,d1)\n",
    "    w2_adj = dot_product(a1,d2)\n",
    "     \n",
    "    # Updating parameters\n",
    "    temp3 = alpha*(w1_adj)\n",
    "    w1_out = w1_in-temp3\n",
    "    temp4 = alpha*(w2_adj)\n",
    "    w2_out = w2_in-temp4\n",
    "    \n",
    "    truth = lambda x: x==0     \n",
    "    return(w1_out, w2_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1 ======== acc: 0.5140845070422535\n",
      "epochs: 2 ======== acc: 0.7464788732394366\n",
      "epochs: 3 ======== acc: 0.8450704225352113\n",
      "epochs: 4 ======== acc: 0.9014084507042254\n",
      "epochs: 5 ======== acc: 0.8943661971830986\n",
      "epochs: 6 ======== acc: 0.8873239436619719\n",
      "epochs: 7 ======== acc: 0.8802816901408451\n",
      "epochs: 8 ======== acc: 0.8943661971830986\n",
      "epochs: 9 ======== acc: 0.9154929577464789\n",
      "epochs: 10 ======== acc: 0.9577464788732394\n",
      "epochs: 11 ======== acc: 0.9436619718309859\n",
      "epochs: 12 ======== acc: 0.9295774647887324\n",
      "epochs: 13 ======== acc: 0.9225352112676056\n",
      "epochs: 14 ======== acc: 0.9577464788732394\n",
      "epochs: 15 ======== acc: 0.9295774647887324\n",
      "epochs: 16 ======== acc: 0.9577464788732394\n",
      "epochs: 17 ======== acc: 0.9225352112676056\n",
      "epochs: 18 ======== acc: 0.9225352112676056\n",
      "epochs: 19 ======== acc: 0.9295774647887324\n",
      "epochs: 20 ======== acc: 0.9225352112676056\n",
      "epochs: 21 ======== acc: 0.9366197183098591\n",
      "epochs: 22 ======== acc: 0.9507042253521126\n",
      "epochs: 23 ======== acc: 0.9436619718309859\n",
      "epochs: 24 ======== acc: 0.9507042253521126\n",
      "epochs: 25 ======== acc: 0.9507042253521126\n",
      "epochs: 26 ======== acc: 0.9436619718309859\n",
      "epochs: 27 ======== acc: 0.9366197183098591\n",
      "epochs: 28 ======== acc: 0.9647887323943662\n",
      "epochs: 29 ======== acc: 0.9507042253521126\n",
      "epochs: 30 ======== acc: 0.9647887323943662\n",
      "epochs: 31 ======== acc: 0.9577464788732394\n",
      "epochs: 32 ======== acc: 0.9647887323943662\n",
      "epochs: 33 ======== acc: 0.9647887323943662\n",
      "epochs: 34 ======== acc: 0.9577464788732394\n",
      "epochs: 35 ======== acc: 0.9859154929577465\n",
      "epochs: 36 ======== acc: 0.9859154929577465\n",
      "epochs: 37 ======== acc: 0.9859154929577465\n",
      "epochs: 38 ======== acc: 0.9859154929577465\n",
      "epochs: 39 ======== acc: 0.9859154929577465\n",
      "epochs: 40 ======== acc: 0.9859154929577465\n",
      "epochs: 41 ======== acc: 0.9859154929577465\n",
      "epochs: 42 ======== acc: 0.9859154929577465\n",
      "epochs: 43 ======== acc: 0.971830985915493\n",
      "epochs: 44 ======== acc: 0.9859154929577465\n",
      "epochs: 45 ======== acc: 0.9859154929577465\n",
      "epochs: 46 ======== acc: 0.971830985915493\n",
      "epochs: 47 ======== acc: 0.9859154929577465\n",
      "epochs: 48 ======== acc: 1.0\n",
      "epochs: 49 ======== acc: 1.0\n",
      "epochs: 50 ======== acc: 1.0\n",
      "epochs: 51 ======== acc: 1.0\n",
      "epochs: 52 ======== acc: 1.0\n",
      "epochs: 53 ======== acc: 1.0\n",
      "epochs: 54 ======== acc: 1.0\n",
      "epochs: 55 ======== acc: 1.0\n",
      "epochs: 56 ======== acc: 1.0\n",
      "epochs: 57 ======== acc: 1.0\n",
      "epochs: 58 ======== acc: 1.0\n",
      "epochs: 59 ======== acc: 1.0\n",
      "epochs: 60 ======== acc: 1.0\n",
      "epochs: 61 ======== acc: 1.0\n",
      "epochs: 62 ======== acc: 1.0\n",
      "epochs: 63 ======== acc: 1.0\n",
      "epochs: 64 ======== acc: 1.0\n",
      "epochs: 65 ======== acc: 1.0\n",
      "epochs: 66 ======== acc: 1.0\n",
      "epochs: 67 ======== acc: 1.0\n",
      "epochs: 68 ======== acc: 1.0\n",
      "epochs: 69 ======== acc: 1.0\n",
      "epochs: 70 ======== acc: 1.0\n",
      "epochs: 71 ======== acc: 1.0\n",
      "epochs: 72 ======== acc: 1.0\n",
      "epochs: 73 ======== acc: 1.0\n",
      "epochs: 74 ======== acc: 1.0\n",
      "epochs: 75 ======== acc: 1.0\n",
      "epochs: 76 ======== acc: 1.0\n",
      "epochs: 77 ======== acc: 1.0\n",
      "epochs: 78 ======== acc: 1.0\n",
      "epochs: 79 ======== acc: 1.0\n",
      "epochs: 80 ======== acc: 1.0\n",
      "epochs: 81 ======== acc: 1.0\n",
      "epochs: 82 ======== acc: 1.0\n",
      "epochs: 83 ======== acc: 1.0\n",
      "epochs: 84 ======== acc: 1.0\n",
      "epochs: 85 ======== acc: 1.0\n",
      "epochs: 86 ======== acc: 1.0\n",
      "epochs: 87 ======== acc: 1.0\n",
      "epochs: 88 ======== acc: 1.0\n",
      "epochs: 89 ======== acc: 1.0\n",
      "epochs: 90 ======== acc: 1.0\n",
      "epochs: 91 ======== acc: 1.0\n",
      "epochs: 92 ======== acc: 1.0\n",
      "epochs: 93 ======== acc: 1.0\n",
      "epochs: 94 ======== acc: 1.0\n",
      "epochs: 95 ======== acc: 1.0\n",
      "epochs: 96 ======== acc: 1.0\n",
      "epochs: 97 ======== acc: 1.0\n",
      "epochs: 98 ======== acc: 1.0\n",
      "epochs: 99 ======== acc: 1.0\n",
      "epochs: 100 ======== acc: 1.0\n",
      "epochs: 101 ======== acc: 1.0\n",
      "epochs: 102 ======== acc: 1.0\n",
      "epochs: 103 ======== acc: 1.0\n",
      "epochs: 104 ======== acc: 1.0\n",
      "epochs: 105 ======== acc: 1.0\n",
      "epochs: 106 ======== acc: 1.0\n",
      "epochs: 107 ======== acc: 1.0\n",
      "epochs: 108 ======== acc: 1.0\n",
      "epochs: 109 ======== acc: 1.0\n",
      "epochs: 110 ======== acc: 1.0\n",
      "epochs: 111 ======== acc: 1.0\n",
      "epochs: 112 ======== acc: 1.0\n",
      "epochs: 113 ======== acc: 1.0\n",
      "epochs: 114 ======== acc: 1.0\n",
      "epochs: 115 ======== acc: 1.0\n",
      "epochs: 116 ======== acc: 1.0\n",
      "epochs: 117 ======== acc: 1.0\n",
      "epochs: 118 ======== acc: 1.0\n",
      "epochs: 119 ======== acc: 1.0\n",
      "epochs: 120 ======== acc: 1.0\n",
      "epochs: 121 ======== acc: 1.0\n",
      "epochs: 122 ======== acc: 1.0\n",
      "epochs: 123 ======== acc: 1.0\n",
      "epochs: 124 ======== acc: 1.0\n",
      "epochs: 125 ======== acc: 1.0\n",
      "epochs: 126 ======== acc: 1.0\n",
      "epochs: 127 ======== acc: 1.0\n",
      "epochs: 128 ======== acc: 1.0\n",
      "epochs: 129 ======== acc: 1.0\n",
      "epochs: 130 ======== acc: 1.0\n",
      "epochs: 131 ======== acc: 1.0\n",
      "epochs: 132 ======== acc: 1.0\n",
      "epochs: 133 ======== acc: 1.0\n",
      "epochs: 134 ======== acc: 1.0\n",
      "epochs: 135 ======== acc: 1.0\n",
      "epochs: 136 ======== acc: 1.0\n",
      "epochs: 137 ======== acc: 1.0\n",
      "epochs: 138 ======== acc: 1.0\n",
      "epochs: 139 ======== acc: 1.0\n",
      "epochs: 140 ======== acc: 1.0\n",
      "epochs: 141 ======== acc: 1.0\n",
      "epochs: 142 ======== acc: 1.0\n",
      "epochs: 143 ======== acc: 1.0\n",
      "epochs: 144 ======== acc: 1.0\n",
      "epochs: 145 ======== acc: 1.0\n",
      "epochs: 146 ======== acc: 1.0\n",
      "epochs: 147 ======== acc: 1.0\n",
      "epochs: 148 ======== acc: 1.0\n",
      "epochs: 149 ======== acc: 1.0\n",
      "epochs: 150 ======== acc: 1.0\n",
      "epochs: 151 ======== acc: 1.0\n",
      "epochs: 152 ======== acc: 1.0\n",
      "epochs: 153 ======== acc: 1.0\n",
      "epochs: 154 ======== acc: 1.0\n",
      "epochs: 155 ======== acc: 1.0\n",
      "epochs: 156 ======== acc: 1.0\n",
      "epochs: 157 ======== acc: 1.0\n",
      "epochs: 158 ======== acc: 1.0\n",
      "epochs: 159 ======== acc: 1.0\n",
      "epochs: 160 ======== acc: 1.0\n",
      "epochs: 161 ======== acc: 1.0\n",
      "epochs: 162 ======== acc: 1.0\n",
      "epochs: 163 ======== acc: 1.0\n",
      "epochs: 164 ======== acc: 1.0\n",
      "epochs: 165 ======== acc: 1.0\n",
      "epochs: 166 ======== acc: 1.0\n",
      "epochs: 167 ======== acc: 1.0\n",
      "epochs: 168 ======== acc: 1.0\n",
      "epochs: 169 ======== acc: 1.0\n",
      "epochs: 170 ======== acc: 1.0\n",
      "epochs: 171 ======== acc: 1.0\n",
      "epochs: 172 ======== acc: 1.0\n",
      "epochs: 173 ======== acc: 1.0\n",
      "epochs: 174 ======== acc: 1.0\n",
      "epochs: 175 ======== acc: 1.0\n",
      "epochs: 176 ======== acc: 1.0\n",
      "epochs: 177 ======== acc: 1.0\n",
      "epochs: 178 ======== acc: 1.0\n",
      "epochs: 179 ======== acc: 1.0\n",
      "epochs: 180 ======== acc: 1.0\n",
      "epochs: 181 ======== acc: 1.0\n",
      "epochs: 182 ======== acc: 1.0\n",
      "epochs: 183 ======== acc: 1.0\n",
      "epochs: 184 ======== acc: 1.0\n",
      "epochs: 185 ======== acc: 1.0\n",
      "epochs: 186 ======== acc: 1.0\n",
      "epochs: 187 ======== acc: 1.0\n",
      "epochs: 188 ======== acc: 1.0\n",
      "epochs: 189 ======== acc: 1.0\n",
      "epochs: 190 ======== acc: 1.0\n",
      "epochs: 191 ======== acc: 1.0\n",
      "epochs: 192 ======== acc: 1.0\n",
      "epochs: 193 ======== acc: 1.0\n",
      "epochs: 194 ======== acc: 1.0\n",
      "epochs: 195 ======== acc: 1.0\n",
      "epochs: 196 ======== acc: 1.0\n",
      "epochs: 197 ======== acc: 1.0\n",
      "epochs: 198 ======== acc: 1.0\n",
      "epochs: 199 ======== acc: 1.0\n",
      "epochs: 200 ======== acc: 1.0\n",
      "epochs: 201 ======== acc: 1.0\n",
      "epochs: 202 ======== acc: 1.0\n",
      "epochs: 203 ======== acc: 1.0\n",
      "epochs: 204 ======== acc: 1.0\n",
      "epochs: 205 ======== acc: 1.0\n",
      "epochs: 206 ======== acc: 1.0\n",
      "epochs: 207 ======== acc: 1.0\n",
      "epochs: 208 ======== acc: 1.0\n",
      "epochs: 209 ======== acc: 1.0\n",
      "epochs: 210 ======== acc: 1.0\n",
      "epochs: 211 ======== acc: 1.0\n",
      "epochs: 212 ======== acc: 1.0\n",
      "epochs: 213 ======== acc: 1.0\n",
      "epochs: 214 ======== acc: 1.0\n",
      "epochs: 215 ======== acc: 1.0\n",
      "epochs: 216 ======== acc: 1.0\n",
      "epochs: 217 ======== acc: 1.0\n",
      "epochs: 218 ======== acc: 1.0\n",
      "epochs: 219 ======== acc: 1.0\n",
      "epochs: 220 ======== acc: 1.0\n",
      "epochs: 221 ======== acc: 1.0\n",
      "epochs: 222 ======== acc: 1.0\n",
      "epochs: 223 ======== acc: 1.0\n",
      "epochs: 224 ======== acc: 1.0\n",
      "epochs: 225 ======== acc: 1.0\n",
      "epochs: 226 ======== acc: 1.0\n",
      "epochs: 227 ======== acc: 1.0\n",
      "epochs: 228 ======== acc: 1.0\n",
      "epochs: 229 ======== acc: 1.0\n",
      "epochs: 230 ======== acc: 1.0\n",
      "epochs: 231 ======== acc: 1.0\n",
      "epochs: 232 ======== acc: 1.0\n",
      "epochs: 233 ======== acc: 1.0\n",
      "epochs: 234 ======== acc: 1.0\n",
      "epochs: 235 ======== acc: 1.0\n",
      "epochs: 236 ======== acc: 1.0\n",
      "epochs: 237 ======== acc: 1.0\n",
      "epochs: 238 ======== acc: 1.0\n",
      "epochs: 239 ======== acc: 1.0\n",
      "epochs: 240 ======== acc: 1.0\n",
      "epochs: 241 ======== acc: 1.0\n",
      "epochs: 242 ======== acc: 1.0\n",
      "epochs: 243 ======== acc: 1.0\n",
      "epochs: 244 ======== acc: 1.0\n",
      "epochs: 245 ======== acc: 1.0\n",
      "epochs: 246 ======== acc: 1.0\n",
      "epochs: 247 ======== acc: 1.0\n",
      "epochs: 248 ======== acc: 1.0\n",
      "epochs: 249 ======== acc: 1.0\n",
      "epochs: 250 ======== acc: 1.0\n",
      "epochs: 251 ======== acc: 1.0\n",
      "epochs: 252 ======== acc: 1.0\n",
      "epochs: 253 ======== acc: 1.0\n",
      "epochs: 254 ======== acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 255 ======== acc: 1.0\n",
      "epochs: 256 ======== acc: 1.0\n",
      "epochs: 257 ======== acc: 1.0\n",
      "epochs: 258 ======== acc: 1.0\n",
      "epochs: 259 ======== acc: 1.0\n",
      "epochs: 260 ======== acc: 1.0\n",
      "epochs: 261 ======== acc: 1.0\n",
      "epochs: 262 ======== acc: 1.0\n",
      "epochs: 263 ======== acc: 1.0\n",
      "epochs: 264 ======== acc: 1.0\n",
      "epochs: 265 ======== acc: 1.0\n",
      "epochs: 266 ======== acc: 1.0\n",
      "epochs: 267 ======== acc: 1.0\n",
      "epochs: 268 ======== acc: 1.0\n",
      "epochs: 269 ======== acc: 1.0\n",
      "epochs: 270 ======== acc: 1.0\n",
      "epochs: 271 ======== acc: 1.0\n",
      "epochs: 272 ======== acc: 1.0\n",
      "epochs: 273 ======== acc: 1.0\n",
      "epochs: 274 ======== acc: 1.0\n",
      "epochs: 275 ======== acc: 1.0\n",
      "epochs: 276 ======== acc: 1.0\n",
      "epochs: 277 ======== acc: 1.0\n",
      "epochs: 278 ======== acc: 1.0\n",
      "epochs: 279 ======== acc: 1.0\n",
      "epochs: 280 ======== acc: 1.0\n",
      "epochs: 281 ======== acc: 1.0\n",
      "epochs: 282 ======== acc: 1.0\n",
      "epochs: 283 ======== acc: 1.0\n",
      "epochs: 284 ======== acc: 1.0\n",
      "epochs: 285 ======== acc: 1.0\n",
      "epochs: 286 ======== acc: 1.0\n",
      "epochs: 287 ======== acc: 1.0\n",
      "epochs: 288 ======== acc: 1.0\n",
      "epochs: 289 ======== acc: 1.0\n",
      "epochs: 290 ======== acc: 1.0\n",
      "epochs: 291 ======== acc: 1.0\n",
      "epochs: 292 ======== acc: 1.0\n",
      "epochs: 293 ======== acc: 1.0\n",
      "epochs: 294 ======== acc: 1.0\n",
      "epochs: 295 ======== acc: 1.0\n",
      "epochs: 296 ======== acc: 1.0\n",
      "epochs: 297 ======== acc: 1.0\n",
      "epochs: 298 ======== acc: 1.0\n",
      "epochs: 299 ======== acc: 1.0\n",
      "epochs: 300 ======== acc: 1.0\n",
      "epochs: 301 ======== acc: 1.0\n",
      "epochs: 302 ======== acc: 1.0\n",
      "epochs: 303 ======== acc: 1.0\n",
      "epochs: 304 ======== acc: 1.0\n",
      "epochs: 305 ======== acc: 1.0\n",
      "epochs: 306 ======== acc: 1.0\n",
      "epochs: 307 ======== acc: 1.0\n",
      "epochs: 308 ======== acc: 1.0\n",
      "epochs: 309 ======== acc: 1.0\n",
      "epochs: 310 ======== acc: 1.0\n",
      "epochs: 311 ======== acc: 1.0\n",
      "epochs: 312 ======== acc: 1.0\n",
      "epochs: 313 ======== acc: 1.0\n",
      "epochs: 314 ======== acc: 1.0\n",
      "epochs: 315 ======== acc: 1.0\n",
      "epochs: 316 ======== acc: 1.0\n",
      "epochs: 317 ======== acc: 1.0\n",
      "epochs: 318 ======== acc: 1.0\n",
      "epochs: 319 ======== acc: 1.0\n",
      "epochs: 320 ======== acc: 1.0\n",
      "epochs: 321 ======== acc: 1.0\n",
      "epochs: 322 ======== acc: 1.0\n",
      "epochs: 323 ======== acc: 1.0\n",
      "epochs: 324 ======== acc: 1.0\n",
      "epochs: 325 ======== acc: 1.0\n",
      "epochs: 326 ======== acc: 1.0\n",
      "epochs: 327 ======== acc: 1.0\n",
      "epochs: 328 ======== acc: 1.0\n",
      "epochs: 329 ======== acc: 1.0\n",
      "epochs: 330 ======== acc: 1.0\n",
      "epochs: 331 ======== acc: 1.0\n",
      "epochs: 332 ======== acc: 1.0\n",
      "epochs: 333 ======== acc: 1.0\n",
      "epochs: 334 ======== acc: 1.0\n",
      "epochs: 335 ======== acc: 1.0\n",
      "epochs: 336 ======== acc: 1.0\n",
      "epochs: 337 ======== acc: 1.0\n",
      "epochs: 338 ======== acc: 1.0\n",
      "epochs: 339 ======== acc: 1.0\n",
      "epochs: 340 ======== acc: 1.0\n",
      "epochs: 341 ======== acc: 1.0\n",
      "epochs: 342 ======== acc: 1.0\n",
      "epochs: 343 ======== acc: 1.0\n",
      "epochs: 344 ======== acc: 1.0\n",
      "epochs: 345 ======== acc: 1.0\n",
      "epochs: 346 ======== acc: 1.0\n",
      "epochs: 347 ======== acc: 1.0\n",
      "epochs: 348 ======== acc: 1.0\n",
      "epochs: 349 ======== acc: 1.0\n",
      "epochs: 350 ======== acc: 1.0\n",
      "epochs: 351 ======== acc: 1.0\n",
      "epochs: 352 ======== acc: 1.0\n",
      "epochs: 353 ======== acc: 1.0\n",
      "epochs: 354 ======== acc: 1.0\n",
      "epochs: 355 ======== acc: 1.0\n",
      "epochs: 356 ======== acc: 1.0\n",
      "epochs: 357 ======== acc: 1.0\n",
      "epochs: 358 ======== acc: 1.0\n",
      "epochs: 359 ======== acc: 1.0\n",
      "epochs: 360 ======== acc: 1.0\n",
      "epochs: 361 ======== acc: 1.0\n",
      "epochs: 362 ======== acc: 1.0\n",
      "epochs: 363 ======== acc: 1.0\n",
      "epochs: 364 ======== acc: 1.0\n",
      "epochs: 365 ======== acc: 1.0\n",
      "epochs: 366 ======== acc: 1.0\n",
      "epochs: 367 ======== acc: 1.0\n",
      "epochs: 368 ======== acc: 1.0\n",
      "epochs: 369 ======== acc: 1.0\n",
      "epochs: 370 ======== acc: 1.0\n",
      "epochs: 371 ======== acc: 1.0\n",
      "epochs: 372 ======== acc: 1.0\n",
      "epochs: 373 ======== acc: 1.0\n",
      "epochs: 374 ======== acc: 1.0\n",
      "epochs: 375 ======== acc: 1.0\n",
      "epochs: 376 ======== acc: 1.0\n",
      "epochs: 377 ======== acc: 1.0\n",
      "epochs: 378 ======== acc: 1.0\n",
      "epochs: 379 ======== acc: 1.0\n",
      "epochs: 380 ======== acc: 1.0\n",
      "epochs: 381 ======== acc: 1.0\n",
      "epochs: 382 ======== acc: 1.0\n",
      "epochs: 383 ======== acc: 1.0\n",
      "epochs: 384 ======== acc: 1.0\n",
      "epochs: 385 ======== acc: 1.0\n",
      "epochs: 386 ======== acc: 1.0\n",
      "epochs: 387 ======== acc: 1.0\n",
      "epochs: 388 ======== acc: 1.0\n",
      "epochs: 389 ======== acc: 1.0\n",
      "epochs: 390 ======== acc: 1.0\n",
      "epochs: 391 ======== acc: 1.0\n",
      "epochs: 392 ======== acc: 1.0\n",
      "epochs: 393 ======== acc: 1.0\n",
      "epochs: 394 ======== acc: 1.0\n",
      "epochs: 395 ======== acc: 1.0\n",
      "epochs: 396 ======== acc: 1.0\n",
      "epochs: 397 ======== acc: 1.0\n",
      "epochs: 398 ======== acc: 1.0\n",
      "epochs: 399 ======== acc: 1.0\n",
      "epochs: 400 ======== acc: 1.0\n",
      "epochs: 401 ======== acc: 1.0\n",
      "epochs: 402 ======== acc: 1.0\n",
      "epochs: 403 ======== acc: 1.0\n",
      "epochs: 404 ======== acc: 1.0\n",
      "epochs: 405 ======== acc: 1.0\n",
      "epochs: 406 ======== acc: 1.0\n",
      "epochs: 407 ======== acc: 1.0\n",
      "epochs: 408 ======== acc: 1.0\n",
      "epochs: 409 ======== acc: 1.0\n",
      "epochs: 410 ======== acc: 1.0\n",
      "epochs: 411 ======== acc: 1.0\n",
      "epochs: 412 ======== acc: 1.0\n",
      "epochs: 413 ======== acc: 1.0\n",
      "epochs: 414 ======== acc: 1.0\n",
      "epochs: 415 ======== acc: 1.0\n",
      "epochs: 416 ======== acc: 1.0\n",
      "epochs: 417 ======== acc: 1.0\n",
      "epochs: 418 ======== acc: 1.0\n",
      "epochs: 419 ======== acc: 1.0\n",
      "epochs: 420 ======== acc: 1.0\n",
      "epochs: 421 ======== acc: 1.0\n",
      "epochs: 422 ======== acc: 1.0\n",
      "epochs: 423 ======== acc: 1.0\n",
      "epochs: 424 ======== acc: 1.0\n",
      "epochs: 425 ======== acc: 1.0\n",
      "epochs: 426 ======== acc: 1.0\n",
      "epochs: 427 ======== acc: 1.0\n",
      "epochs: 428 ======== acc: 1.0\n",
      "epochs: 429 ======== acc: 1.0\n",
      "epochs: 430 ======== acc: 1.0\n",
      "epochs: 431 ======== acc: 1.0\n",
      "epochs: 432 ======== acc: 1.0\n",
      "epochs: 433 ======== acc: 1.0\n",
      "epochs: 434 ======== acc: 1.0\n",
      "epochs: 435 ======== acc: 1.0\n",
      "epochs: 436 ======== acc: 1.0\n",
      "epochs: 437 ======== acc: 1.0\n",
      "epochs: 438 ======== acc: 1.0\n",
      "epochs: 439 ======== acc: 1.0\n",
      "epochs: 440 ======== acc: 1.0\n",
      "epochs: 441 ======== acc: 1.0\n",
      "epochs: 442 ======== acc: 1.0\n",
      "epochs: 443 ======== acc: 1.0\n",
      "epochs: 444 ======== acc: 1.0\n",
      "epochs: 445 ======== acc: 1.0\n",
      "epochs: 446 ======== acc: 1.0\n",
      "epochs: 447 ======== acc: 1.0\n",
      "epochs: 448 ======== acc: 1.0\n",
      "epochs: 449 ======== acc: 1.0\n",
      "epochs: 450 ======== acc: 1.0\n",
      "epochs: 451 ======== acc: 1.0\n",
      "epochs: 452 ======== acc: 1.0\n",
      "epochs: 453 ======== acc: 1.0\n",
      "epochs: 454 ======== acc: 1.0\n",
      "epochs: 455 ======== acc: 1.0\n",
      "epochs: 456 ======== acc: 1.0\n",
      "epochs: 457 ======== acc: 1.0\n",
      "epochs: 458 ======== acc: 1.0\n",
      "epochs: 459 ======== acc: 1.0\n",
      "epochs: 460 ======== acc: 1.0\n",
      "epochs: 461 ======== acc: 1.0\n",
      "epochs: 462 ======== acc: 1.0\n",
      "epochs: 463 ======== acc: 1.0\n",
      "epochs: 464 ======== acc: 1.0\n",
      "epochs: 465 ======== acc: 1.0\n",
      "epochs: 466 ======== acc: 1.0\n",
      "epochs: 467 ======== acc: 1.0\n",
      "epochs: 468 ======== acc: 1.0\n",
      "epochs: 469 ======== acc: 1.0\n",
      "epochs: 470 ======== acc: 1.0\n",
      "epochs: 471 ======== acc: 1.0\n",
      "epochs: 472 ======== acc: 1.0\n",
      "epochs: 473 ======== acc: 1.0\n",
      "epochs: 474 ======== acc: 1.0\n",
      "epochs: 475 ======== acc: 1.0\n",
      "epochs: 476 ======== acc: 1.0\n",
      "epochs: 477 ======== acc: 1.0\n",
      "epochs: 478 ======== acc: 1.0\n",
      "epochs: 479 ======== acc: 1.0\n",
      "epochs: 480 ======== acc: 1.0\n",
      "epochs: 481 ======== acc: 1.0\n",
      "epochs: 482 ======== acc: 1.0\n",
      "epochs: 483 ======== acc: 1.0\n",
      "epochs: 484 ======== acc: 1.0\n",
      "epochs: 485 ======== acc: 1.0\n",
      "epochs: 486 ======== acc: 1.0\n",
      "epochs: 487 ======== acc: 1.0\n",
      "epochs: 488 ======== acc: 1.0\n",
      "epochs: 489 ======== acc: 1.0\n",
      "epochs: 490 ======== acc: 1.0\n",
      "epochs: 491 ======== acc: 1.0\n",
      "epochs: 492 ======== acc: 1.0\n",
      "epochs: 493 ======== acc: 1.0\n",
      "epochs: 494 ======== acc: 1.0\n",
      "epochs: 495 ======== acc: 1.0\n",
      "epochs: 496 ======== acc: 1.0\n",
      "epochs: 497 ======== acc: 1.0\n",
      "epochs: 498 ======== acc: 1.0\n",
      "epochs: 499 ======== acc: 1.0\n",
      "epochs: 500 ======== acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "lr = 0.01\n",
    "w1 = generate_wt(13, 100)\n",
    "w2 = generate_wt(100,3)\n",
    "check = lambda x: x==0\n",
    "for j in range(epochs):\n",
    "    temp = 0\n",
    "    for idx in range(len(x_train)):\n",
    "        out = forward(x_train[idx],w1,w2)\n",
    "        losss = loss(out, y_train[idx])\n",
    "        if check(losss):\n",
    "            temp += 1\n",
    "        w1, w2 = back_prop(x_train[idx], y_train[idx], w1, w2, lr)\n",
    "    print(\"epochs:\", j + 1, \"======== acc:\", (temp/len(x_train))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[0 0 1]\n",
      "Predicted Class: 3, Actual Class: 3\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[0 0 1]\n",
      "Predicted Class: 3, Actual Class: 3\n",
      "[0 0 1]\n",
      "Predicted Class: 3, Actual Class: 3\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[0 0 1]\n",
      "Predicted Class: 3, Actual Class: 3\n",
      "[0 1 0]\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[0 0 1]\n",
      "Predicted Class: 3, Actual Class: 3\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[0 0 1]\n",
      "Predicted Class: 3, Actual Class: 3\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[0 0 1]\n",
      "Predicted Class: 3, Actual Class: 3\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[0 0 1]\n",
      "Predicted Class: 3, Actual Class: 3\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "[1 0 0]\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "[0 1 0]\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def predict(x, y, w1, w2, use_decode_spec=False):\n",
    "    Out = forward(x, w1, w2)\n",
    "    for i in range(len(Out)):\n",
    "        if Out[i] == 1:\n",
    "            if use_decode_spec:\n",
    "                y = decode_spec(y)\n",
    "            else:\n",
    "                y = decode(y)\n",
    "            print(f\"Predicted Class: {i+1}, Actual Class: {y}\")\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "correct_predictions = 0\n",
    "for idx in range(len(x_test)):\n",
    "    predict(x_test[idx], y_test[idx], w1, w2)\n",
    "    correct_predictions += 1\n",
    "print(correct_predictions/len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\Users\\kanin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 2\n",
      "Predicted Class: 1, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 2\n",
      "Predicted Class: 3, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 2\n",
      "Predicted Class: 2, Actual Class: 1\n",
      "Average prediction of the 5 cross-folds: 0.97\n"
     ]
    }
   ],
   "source": [
    "df_copy = df\n",
    "splits=5\n",
    "kf = KFold(n_splits=splits, shuffle=True)\n",
    "data = df_copy.values\n",
    "np.random.shuffle(data)\n",
    "folds = np.array_split(data, 5)\n",
    "epochs = 500\n",
    "lr = 0.01\n",
    "accuracy = 0\n",
    "fold_classes = []\n",
    "for fold in folds:\n",
    "    classes = []\n",
    "    for row in fold:\n",
    "        c = (row[0])\n",
    "        row = np.delete(row, 0)\n",
    "        classes += [convert([int(c)])][0]\n",
    "    fold_classes += [classes]\n",
    "fold_classes = np.array(fold_classes)\n",
    "\n",
    "for i in range(len(folds)):\n",
    "    fold = np.delete(folds[i], 0, axis=1)\n",
    "    folds[i] = fold\n",
    "\n",
    "for fold_idx in range(len(folds)):\n",
    "    prev_fold = 0\n",
    "    prev_fold_classes = 0\n",
    "    for other_fold_idx in range(len(folds)):\n",
    "        if fold_idx == other_fold_idx:\n",
    "            continue\n",
    "        if type(prev_fold) == type(0):\n",
    "            prev_fold = folds[other_fold_idx]\n",
    "            prev_fold_classes = fold_classes[other_fold_idx]\n",
    "        else:\n",
    "            np.concatenate((prev_fold, folds[other_fold_idx]), axis=0)\n",
    "            np.concatenate((prev_fold_classes, fold_classes[other_fold_idx]), axis=0)\n",
    "    w1 = generate_wt(13, 100)\n",
    "    w2 = generate_wt(100,3)\n",
    "    check = lambda x: x==0\n",
    "    for j in range(epochs):\n",
    "        temp = 0\n",
    "        for idx in range(len(prev_fold)):\n",
    "            out = forward(prev_fold[idx],w1,w2)\n",
    "            losss = loss(out, prev_fold_classes[fold_idx])\n",
    "            if check(losss):\n",
    "                temp += 1\n",
    "            w1, w2 = back_prop(prev_fold[idx], prev_fold_classes[fold_idx], w1, w2, lr)\n",
    "            \n",
    "    correct_predictions = 0\n",
    "    fold = folds[i]\n",
    "    output = fold_classes[i]\n",
    "    for k in range(len(fold)):\n",
    "        predict(fold[k], output[k], w1, w2, use_decode_spec=True)\n",
    "        correct_predictions += 1\n",
    "    accuracy += correct_predictions/len(x_test)\n",
    "    \n",
    "print(f\"Average prediction of the {splits} cross-folds: {accuracy/splits:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project was challenging not just because I was unable to use common machine learning libraries but because I was forced to critically think through how a Multilayer Perceptron model really works. My model manages to average above 95% accuracy after many many hours of work. I believe I should expect a slightly lower accuracy though as I am not taking into account parameter penalization. I would love to keep working iwht this perceptron to see how many layers really make it \"optimal\".  Also, I am unsure if my model being fully connected impacts the overall accuracy or not, but I think removing some connections could be interesting. I feel like I learned quite a bit about feed forward networks and how back propogation works. I enjoyed working on this project qute a bit, and I can't wait to see what we do next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit to the following\n",
    "- https://towardsdatascience.com/neural-net-from-scratch-using-numpy-71a31f6e3675\n",
    "- https://medium.com/analytics-vidhya/neural-network-mnist-classifier-from-scratch-using-numpy-library-94bbcfed7eae\n",
    "- https://www.geeksforgeeks.org/implementation-of-neural-network-from-scratch-using-numpy/\n",
    "- https://machinelearninggeek.com/multi-layer-perceptron-neural-network-using-python/\n",
    "- https://www.youtube.com/watch?v=0oWnheK-gGk\n",
    "- https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "- Peers: Alex Kiefer\n",
    "- Dr. Tang's comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
